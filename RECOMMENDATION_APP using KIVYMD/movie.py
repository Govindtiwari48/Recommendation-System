#!/usr/bin/env python
# coding: utf-8

# In[1]:


# Working:User will give a movie name as input and we'll recommend any 5 movies which are similar to it
import numpy as np
import pandas as pd

# In[2]:


movies = pd.read_csv(
    r"/Users/govindtiwari/Documents/ Python Codes/application using kivy/START_APP/tmdb_5000_movies.csv")
credits = pd.read_csv(
    r"/Users/govindtiwari/Documents/ Python Codes/application using kivy/START_APP/tmdb_5000_credits.csv")

# In[3]:


movies.head(1)

# In[4]:


credits.head(1)

#

# In[5]:


movies = movies.merge(credits, on='title')

# movies.head(1)

# In[6]:


movies.head(1)

# In[7]:


# Sorting columns which will be useful in our recommendation
# genres
# id
# keywords
# title
# overview
# cast
# crew
movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

# In[8]:


# movies['original_language'].value_counts()


# In[9]:


movies.info()

# In[10]:


movies.head()

# In[11]:


# Now we'll create a dataframe which will contain [movie_id,title,tag].Now, tag column will be generated by merging overview,
# genres,keyword,cast and crew columns


# In[12]:


movies.isnull()

# In[13]:


movies.isnull().sum()

# In[14]:


# Used to drop those rows whose isnull value is True
movies.dropna(inplace=True)

# In[15]:


movies.isnull().sum()

# In[16]:


# To check whether any rows are duplicate or not
movies.duplicated().sum()

# In[17]:


# Starting with genres
movies.iloc[0].genres

# In[18]:


# Now we need to turn this:->'[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]'
# Into this:->[Action,Adventure,....]


# In[19]:


import ast


def convert(obj):
    l = []
    for i in ast.literal_eval(obj):
        l.append(i["name"])
    return l


# In[20]:


# Now we need to covnvert genre from string data type to list
import ast

ast.literal_eval(
    '[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')

# In[21]:


movies['genres'] = movies['genres'].apply(convert)

# In[22]:


movies.head()

# In[23]:


movies['keywords'] = movies['keywords'].apply(convert)

# In[24]:


movies.head()

# In[25]:


# del movies["keyword"]


# In[26]:


movies.head()


# In[27]:


# this function is used to get first three cast from each film in list form
def convert2(obj):
    l = []
    counter = 0
    for i in ast.literal_eval(obj):
        if counter != 3:
            l.append(i["name"])
            counter += 1
        else:
            break
    return l


# In[28]:


movies['cast'] = movies['cast'].apply(convert2)

# In[29]:


movies.head()


# In[30]:


# Now for crew we'll extract the name from the dictionary where job is director
def convert3(obj):
    l = []
    for i in ast.literal_eval(obj):
        if i['job'] == "Director":
            l.append(i["name"])
            break
    return l


# In[31]:


movies['crew'] = movies['crew'].apply(convert3)

# In[32]:


movies.head()

# In[33]:


# to convert overview from string to a list form(so that we can further concatenate)
movies['overview'] = movies['overview'].apply(lambda x: x.split())

# In[34]:


movies.head()

# In[35]:


# Now we need to remove spaces between in names else our recommender will confuse b/w sam worthington and sam mendes
movies['genres'] = movies['genres'].apply(lambda x: [i.replace(" ", "") for i in x])
movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(" ", "") for i in x])
movies['cast'] = movies['cast'].apply(lambda x: [i.replace(" ", "") for i in x])
movies['crew'] = movies['crew'].apply(lambda x: [i.replace(" ", "") for i in x])

# In[36]:


movies.head()

# In[37]:


# Now we'll make a new column 'tag' on the basis of which our recommendation system will work
movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

# In[38]:


movies.head()

# In[39]:


new_df = movies[['movie_id', 'title', 'tags']]

# In[ ]:


# In[40]:


new_df.loc[:, 'tags'] = new_df['tags'].apply(lambda x: " ".join(x))

# In[41]:


new_df.head()

# In[42]:


# Stemming
# Applying stemming->convert all the words to their base form
# ['dancing','dance','danced']->['dance','dance','dance']
import nltk

# In[43]:


from nltk.stem.porter import PorterStemmer

ps = PorterStemmer()


# In[44]:


def stem(text):
    y = []
    for i in text.split():
        y.append(ps.stem(i))

    return " ".join(y)


# In[45]:


new_df['tags'][0]

# In[46]:


new_df.loc[:, 'tags'] = new_df['tags'].apply(stem)

# In[47]:


# Now it is recommended to keep all the tags in lowercase
new_df.loc[:, 'tags'] = new_df['tags'].apply(lambda x: x.lower())

# In[48]:


# Vectorization of tags Represent all the tags in a vector format and recommend any 5 movie's vector closest to the
# input movie's vector ->text converted to vectors(text vectorization) ->techniques ->bag of words(simplest,
# one which we are gonna use), ->tfidf,->word2vec ->bag of words->We'll combine all the tags into a one single large
# tag and from that we'll extract some N numbers of most commonly used words Now,for eg.: We'll apply operations on
# tags column and will get a table of 5000 most commonly occuring words Action|Future......Alien movie1     5     2
# 1 movie2     3     1            4 . . . Now each row is a vector containing which commonly occuring word occured
# how many time in that movie's tag We'll not include stop words in the table of "commonly occuring words" Stop
# words:Words which are used for sentence formation eg. is,an,are etc.


# In[49]:


# We'll use scikit learn for vectorization
from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer(max_features=5000, stop_words='english')

# In[50]:


# this will create an array or table of vectors
#         Action|Future......Alien
# movie1     5     2            1
# movie2     3     1            4
# .
# .
# .
vectors = cv.fit_transform(new_df['tags']).toarray()

# In[51]:


vectors

# In[52]:


vectors[0]

# In[53]:


cv.get_feature_names_out()

# In[54]:


# Now in vectorization the movies will be plotted according to their 'vectors table value' and then we'll calculate the
# distance of a movie from every other movie...the closer the movie the similar it is
# NOTE:We'll not calculate Eucledian distance(direct head to head distance) but their cosine distance(angle between them)
# cause in high dimensions(5000 here) Eucledian distance tends to fail or not a reliable measure


# In[55]:


from sklearn.metrics.pairwise import cosine_similarity

# In[56]:


# cosine_similarity(between 0 to 1)
similarity = cosine_similarity(vectors)

# In[57]:


# Syntax to fetch the index of a movie
new_df[new_df["title"] == 'Batman Begins'].index[0]

# In[58]:


# syntax to sort the movies on the basis of their cosine similarity with the movie at'0' index
# the list is sorted in descending order i.e. the movies with higher cosine similarity will be more similar
# enumerate is used to convert list of cosine similarity into list of tuple(index,cosine similarity)
sorted(list(enumerate(similarity[0])), reverse=True, key=lambda x: x[1])


# In[59]:


def recommend(movie):
    s = ""
    movie_index = new_df[new_df['title'] == movie].index[0]
    distances = similarity[movie_index]
    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:]
    for i in movies_list:
        s = s + new_df.iloc[i[0]].title +"  "
    return s
